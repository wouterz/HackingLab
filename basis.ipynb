{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Layer\n",
    "from keras_applications import inception_v3, inception_resnet_v2, resnet\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models, paper uses : \n",
    "# - Inception V3, V3 adv & V4, (adv is pre trained)\n",
    "# - Inception Resnet V2\n",
    "# - Resnet V2 152, 150 & 50\n",
    "\n",
    "# https://keras.io/applications\n",
    "input_tensor = Input(shape=(299, 299, 3))\n",
    "i_v3_model = inception_v3.InceptionV3(weights='imagenet', input_tensor=input_tensor,\n",
    "    backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "\n",
    "# i_rn_v2_model = inception_resnet_v2.InceptionResNetV2(weights='imagenet', input_tensor=input_tensor,\n",
    "#     backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "\n",
    "# rn50_model = resnet.ResNet50(weights='imagenet', input_tensor=input_tensor,\n",
    "#     backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "\n",
    "# rn152_model = resnet.ResNet152(weights='imagenet', input_tensor=input_tensor,\n",
    "#     backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RN50 = 'RN50'\n",
    "RN152 = 'RN152'\n",
    "I_V3 = 'I_V3'\n",
    "I_RN_V2 = 'I_RN_V2'\n",
    "\n",
    "\n",
    "#Execute classification\n",
    "def classify(img, model):\n",
    "\n",
    "    # ugly\n",
    "    if model == 'RN50':\n",
    "        model = rn50_model\n",
    "        application = resnet\n",
    "    elif model == 'RN152':\n",
    "        model = rn152_model\n",
    "        application = resnet\n",
    "    elif model == 'I_V3':\n",
    "        model = i_v3_model\n",
    "        application = inception_v3\n",
    "    elif model == 'I_RN_V2':\n",
    "        model = i_rn_v2_model\n",
    "        application = inception_resnet_v2\n",
    "        \n",
    "    # preprocess\n",
    "    img_prep = image.img_to_array(img)\n",
    "    img_prep = np.expand_dims(img_prep, axis=0)\n",
    "    img_prep = application.preprocess_input(img_prep,\n",
    "        backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "    # predict\n",
    "    predictions = model.predict(img_prep)\n",
    "    #results\n",
    "    return application.decode_predictions(predictions, top=2, utils=keras.utils)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img_path = 'images/test_elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "center_size = 79\n",
    "start = int((299 - center_size) / 2)\n",
    "end = int((299 - center_size) / 2 + center_size)\n",
    "\n",
    "\n",
    "img_center = img.resize((center_size,center_size))\n",
    "pixels_center = np.array(img_center)/255\n",
    "\n",
    "#zeros = np.full((299,299,3), 0, dtype=np.int)\n",
    "#zeros = np.random.rand(299,299,3)\n",
    "zeros = np.random.rand(299,299,3)\n",
    "zeros[start:end, start:end, :] = 0;\n",
    "plt.imshow(zeros)\n",
    "plt.show()\n",
    "\n",
    "zeros = np.tanh(np.multiply(zeros, zeros));\n",
    "zeros[start:end, start:end, :] = pixels_center\n",
    "plt.imshow(zeros)\n",
    "plt.show()\n",
    "#print(classify(img, I_V3))\n",
    "# print(classify(img, I_RN_V2))\n",
    "# print(classify(img, RN50))\n",
    "# print(classify(img, RN152))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "center_size = 79\n",
    "start = int((299 - center_size) / 2)\n",
    "end = int((299 - center_size) / 2 + center_size)\n",
    "\n",
    "\n",
    "img_center = img.resize((center_size,center_size))\n",
    "pixels_center = np.array(img_center)\n",
    "\n",
    "zeros = np.full((299,299,3), 0, dtype=np.int)\n",
    "zeros[start:end, start:end, :] = pixels_center\n",
    "\n",
    "plt.imshow(zeros)\n",
    "plt.show()\n",
    "#print(classify(zeros, I_V3))\n",
    "\n",
    "adv_program = np.random.rand(299,299,3) * 255\n",
    "adv_program = adv_program.astype(int)\n",
    "adv_program[start:end, start:end, :] = pixels_center\n",
    "plt.imshow(adv_program)\n",
    "plt.show()\n",
    "#print(classify(adv_program, I_V3))\n",
    "\n",
    "#print(input_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(images, adv_program):\n",
    "    results = []\n",
    "    for class_images in images:\n",
    "        class_results = []\n",
    "        for img in class_images:\n",
    "            adv_program[start:end, start:end, :] = img\n",
    "            # plt.imshow(adv_program)\n",
    "            # plt.show()\n",
    "            class_results.append(classify(adv_program, I_V3)[0][1])\n",
    "        results.append(class_results)\n",
    "\n",
    "        if not (class_results.count(class_results[0]) == len(class_results)):\n",
    "            return (False, results)\n",
    "        \n",
    "    return (True, results)\n",
    " \n",
    "\n",
    "\n",
    "def getImage(name):\n",
    "    return image.load_img('images/'+name+'.png', target_size=(center_size, center_size))\n",
    "\n",
    "def classImages(nr):\n",
    "    class_names = [nr+'_1', nr+'_2', nr+'_3']\n",
    "    return [getImage(name) for name in class_names]\n",
    "    \n",
    "\n",
    "adv_program = np.random.rand(299,299,3) * 255\n",
    "adv_program = adv_program.astype(int)\n",
    "\n",
    "test([classImages('2'), classImages('6')], adv_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "for i in itertools.count(0):\n",
    "    adv_program = np.random.rand(299,299,3) * 255\n",
    "    adv_program = adv_program.astype(int)\n",
    "\n",
    "    result = test([classImages('2'), classImages('6')], adv_program)\n",
    "    clear_output(wait=True)\n",
    "    display(i, result[1])\n",
    "\n",
    "    if result[0]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adv_program)\n",
    "plt.show()\n",
    "import pickle\n",
    "pickle.dump(adv_program, open('adv_program', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from math import log, inf\n",
    "\n",
    "def evaluate(images: {str: []}, adv_program: []):\n",
    "    results = {}\n",
    "    for k, class_images in images.items():\n",
    "        class_results = []\n",
    "        for img in class_images:\n",
    "            adv_program[start:end, start:end, :] = img\n",
    "#             Append best match\n",
    "            class_results.append(classify(adv_program, I_V3)[0][1])\n",
    "        \n",
    "        results[k] = class_results\n",
    "    return results\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "valueDict = dict()\n",
    "keyDict = dict()\n",
    "\n",
    "def results_to_matrix(results):\n",
    "    keys = results.keys()\n",
    "    for key in keys:\n",
    "        if(key not in keyDict.keys()):\n",
    "            keyDict[key]=len(keyDict.keys());\n",
    "    values = set(flatten(results.values()))\n",
    "    for val in values:\n",
    "        if(val not in valueDict.keys()):\n",
    "            valueDict[val]=len(valueDict.keys())\n",
    " #   if(isinstance(matrix, list)):\n",
    "    matrix = np.zeros((len(keys), len(valueDict.keys())))\n",
    "    for i in results.keys():\n",
    "        for j in results[i]:\n",
    "            matrix[keyDict[i]][valueDict[j]]+=1\n",
    "    #for value in results.values():\n",
    "    #    el=[]\n",
    "    #    for c in classes: el.append(value.count(c))\n",
    "    #    matrix.append(el)\n",
    "    return matrix\n",
    "\n",
    "def computeMatrixLoss(matrix):\n",
    "    matrix = matrix/matrix.sum(axis=1)[:,None]\n",
    "    usedLabels = []\n",
    "    loss=0\n",
    "    matrix = matrix.transpose()\n",
    "    for i in matrix:\n",
    "        highestProbability = 0;\n",
    "        probabilityID = inf;\n",
    "        for j in range(0,len(i)):\n",
    "            if(j not in usedLabels):\n",
    "                if(i[j]>=highestProbability):\n",
    "                    highestProbability=i[j]\n",
    "                    probabilityID=j\n",
    "        usedLabels.append(probabilityID)\n",
    "        if(highestProbability==0):\n",
    "            loss = loss+10\n",
    "        else:\n",
    "            loss = loss - log(highestProbability);\n",
    "    loss = loss+(len(matrix[1])-len(matrix))*10\n",
    "    return loss\n",
    "\n",
    "def computeLoss(results: {str: []}):\n",
    "    label_map = dict()\n",
    "    loss = 0\n",
    "    for k, class_result in results.items():\n",
    "        \n",
    "        most_common = max(set(class_result), key = class_result.count)\n",
    "        count = class_result.count(most_common)\n",
    "        probability = count/len(class_result)\n",
    "        \n",
    "        label_map[k]= most_common\n",
    "        loss = loss - log(probability)\n",
    "            \n",
    "    print(loss)\n",
    "    return loss\n",
    "\n",
    "# computeLoss({'1':[1,2,2,2,2,3], '2': [2,3,4,3,3,3,1,3,34,4,4,4,4,4]})\n",
    "\n",
    "CENTER_SIZE = 29\n",
    "LABELS = ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "import glob\n",
    "\n",
    "def loadImages():\n",
    "    images = dict()\n",
    "    \n",
    "    for label in LABELS:\n",
    "        files = glob.glob(\"allSquares/squares\"+label+\"_*.png\")\n",
    "        images[label] = [image.load_img(f, target_size=(CENTER_SIZE, CENTER_SIZE)) for f in files[:10]]\n",
    "\n",
    "    return images\n",
    "\n",
    "def train():\n",
    "    best_adv_program = []\n",
    "    best_loss = inf\n",
    "    \n",
    "    images = loadImages()\n",
    "    bestMatrix = []\n",
    "    try:\n",
    "        for i in itertools.count(0):\n",
    "\n",
    "            adv_program = np.random.rand(299,299,3) * 255\n",
    "            adv_program = adv_program.astype(int)\n",
    "\n",
    "            result = evaluate(images, adv_program)\n",
    "            mresult = results_to_matrix(result)\n",
    "            #loss = computeLoss(result)\n",
    "            loss = computeMatrixLoss(mresult)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_adv_program = adv_program\n",
    "                bestMatrix = mresult\n",
    "                clear_output(wait=True)\n",
    "                display(i, best_loss)\n",
    "            print(i, end='\\r')\n",
    "\n",
    "            if loss < 0.05:\n",
    "                break\n",
    "        return (best_adv_program, bestMatrix);\n",
    "    except:\n",
    "        return (best_adv_program, bestMatrix);\n",
    "print(train()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program to find most frequent \n",
    "# element in a list \n",
    "def most_frequent(List):\n",
    "    print(List)\n",
    "    print(set(List))\n",
    "    return max(set(List), key = List.count) \n",
    "\n",
    "List = [2, 1, 2, 2, 1, 3] \n",
    "print(most_frequent(List))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "#(xt, yt), (xte, yte) = mnist.load_data()\n",
    "print(xt[0], yt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_size = 29\n",
    "input_tensor = Input(shape=(299, 299, 3))\n",
    "class AdvLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdvLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        img_shape = (299,299,3)\n",
    "        self.adv_weights = self.add_weight(name='kernel', \n",
    "                                      shape=img_shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(AdvLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        start = int((299 - center_size) / 2)\n",
    "        end = int((299 - center_size) / 2 + center_size)\n",
    "\n",
    "        adv_img = np.full((299,299,3), 1, dtype=np.float)\n",
    "        adv_img[start:end, start:end, :] = 0;\n",
    "        padx = tf.pad(tf.concat([x], axis=-1),\n",
    "                      paddings = tf.constant([[0,0], [start, start], [start, start], [0,0]]))\n",
    "        print(padx.shape)\n",
    "        adv_img = tf.nn.tanh(tf.multiply(self.adv_weights, adv_img))+padx;\n",
    "        #adv_img[start:end, start:end, :] = x\n",
    "        self.out_shape = adv_img.shape\n",
    "\n",
    "        return adv_img;\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.out_shape\n",
    "inputs = Input(shape=(center_size, center_size, 3))\n",
    "inception = inception_v3.InceptionV3(weights='imagenet', input_tensor=input_tensor,\n",
    "    backend=keras.backend, layers=keras.layers, models=keras.models, utils=keras.utils)\n",
    "inception.trainable = False;\n",
    "al = AdvLayer()(inputs)\n",
    "outputs = inception(al)\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "print(model.summary())\n",
    "model.compile(optimizer = Adam(lr=0.05, decay=0.96),\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = loadImages()\n",
    "inputList = []\n",
    "outputList = []\n",
    "for key in images.keys():\n",
    "    for value in images[key]:\n",
    "        array = np.zeros(1000)\n",
    "        array[int(key)]=1\n",
    "        newvalue = np.asarray(value)/255\n",
    "        newvalue = (newvalue-0.5)*2;\n",
    "        inputList.append(np.asarray(value));\n",
    "        outputList.append(array);\n",
    "    totalNr = len(images[key])\n",
    "    while(totalNr<10):\n",
    "        inputList.append(np.asarray(value));\n",
    "        outputList.append(array);\n",
    "        totalNr+=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputa = np.array(inputList)\n",
    "outputa = np.array(outputList)\n",
    "print(inputa.shape)\n",
    "print(outputa.shape)\n",
    "model.fit(inputa, outputa,\n",
    "                epochs=1200,\n",
    "                batch_size=25,\n",
    "                validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}